{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Projet LEYENDA\n",
    "## Livrable 1 - Classification Binaire"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bbcdab41f7ad26c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1-Importation des bibliothèques\n",
    "On va regrouper ici l'ensemble des bibliothèques que nous allons utiliser dans ce nootbook"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7705d02550f9b2d"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Applications\\Annaconda\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import zipfile\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T08:38:42.638927Z",
     "start_time": "2023-10-09T08:37:51.782858300Z"
    }
   },
   "id": "4ff84e3050962ffd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2-Préparation des images\n",
    "#### Dézip des fichiers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab9c6473dd452b67"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier Dataset Livrable 1 - Painting.zip décompressé dans le dossier Dataset.\n",
      "Fichier Dataset Livrable 1 - Photo.zip décompressé dans le dossier Dataset.\n",
      "Fichier Dataset Livrable 1 - Schematics.zip décompressé dans le dossier Dataset.\n",
      "Fichier Dataset Livrable 1 - Sketch.zip décompressé dans le dossier Dataset.\n",
      "Fichier Dataset Livrable 1 - Text.zip décompressé dans le dossier Dataset.\n",
      "Tous les fichiers ZIP ont été décompressés dans le dossier Dataset\n"
     ]
    }
   ],
   "source": [
    "repertoire = 'D:/Ecole/2023-2024 A5/Data Scientist/Projet/DataL1'\n",
    "dossier_dataset = 'D:/Ecole/2023-2024 A5/Data Scientist/Projet/Data'\n",
    "if not os.path.exists(dossier_dataset):\n",
    "    os.makedirs(dossier_dataset)\n",
    "    \n",
    "for fichier in os.listdir(repertoire):\n",
    "    chemin_fichier = os.path.join(repertoire,fichier)\n",
    "    if zipfile.is_zipfile(chemin_fichier):\n",
    "        with zipfile.ZipFile(chemin_fichier, 'r') as zip_ref:\n",
    "            zip_ref.extractall(dossier_dataset)\n",
    "            print(f'Fichier {fichier} décompressé dans le dossier Dataset.')\n",
    "print('Tous les fichiers ZIP ont été décompressés dans le dossier Dataset')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T13:52:02.314729500Z",
     "start_time": "2023-10-06T13:46:28.084792100Z"
    }
   },
   "id": "f5ec94da62cf051e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Emplacement du dataset\n",
    "On spécifie ensuite l'emplacement du dataset et on met en place la variable data_dir."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc79384cddaa1e06"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dossier_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_11112\\110700200.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdatapath\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdossier_dataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mdata_dir\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpathlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mPath\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdatapath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dossier_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "datapath = dossier_dataset\n",
    "data_dir = pathlib.Path(datapath)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T08:38:44.836221200Z",
     "start_time": "2023-10-09T08:38:42.638927Z"
    }
   },
   "id": "55e8603cf19c764c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Création des Set\n",
    "Pour commencer, on spécifie quelques paramètres pour l'apprentissage :\n",
    "<ul>\n",
    "    <li>La longueur et la largeur des images. </li>\n",
    "    <li>La taille du batch.</li>\n",
    "</ul>\n",
    "On crée maintenant nos deux sets, un d'entraînement (80% des data) et un de test (20% des data)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adbba4b481bd2b7d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_h = 180\n",
    "image_w = 180\n",
    "batch_s = 32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T08:38:44.836221200Z"
    }
   },
   "id": "2421b5f437d9cb68"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Le train_set\n",
    "train_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=  0.2,\n",
    "    subset =  \"training\",\n",
    "    seed=42,\n",
    "    image_size=(image_h, image_w),\n",
    "    batch_size=batch_s\n",
    ")\n",
    "# Le test_set\n",
    "test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=  0.2,\n",
    "    subset =  \"validation\",\n",
    "    seed=42,\n",
    "    image_size=(image_h, image_w),\n",
    "    batch_size=batch_s\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ebeaf5921868e37c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "On en profite pour vérifier que les labels ont bien été trouvés :"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30430c14ac8d839e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_names = train_set.class_names\n",
    "print(class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ae9a6d420817ad65"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 - Coup d'œil sur nos données\n",
    "On peut affichage une des images du set d'entraînements, aux dimensions spécifiées dans les paramètres :"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "641956c8d7dbedd7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for images, labels in train_set.take(1):\n",
    "    for i in range(9):\n",
    "        ax =  plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7de352088c714a3d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il est maintenant temps de configurer notre environnement pour passer au vif du sujet.\n",
    "\n",
    "# 3. Configuration de l'environnement pour l'entrainement\n",
    "Dans cette partie, vous devrez utiliser les fonctions [`Dataset.cache`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#cache) et [`Dataset.prefetch`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch) afin de configurer les données pour améliorer les performances de la façon suivante :\n",
    "- `Dataset.cache()` : Cette fonction sert à forcer le maintien des données en cache dans la mémoire. Vu que le réseau de neurones fait plusieurs passes (qu'on nomme _époque_ ou _epoch_ en anglais) sur les données durant l'apprentissage, cette fonction permet de ne pas avoir à recharger les images à chaque fois. \n",
    "- `Dataset.prefetch()` : Cette fonction permet de faire le prétraitement de l'élément courant du jeu de données (par exemple le batch suivant) en même temps que l'entrainement/évaluation du batch courant par le modèle. Dans un environnement multi-processeurs ou multi-cœur, c'est un gain de temps non négligeable."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "faba81968af59c2a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_set = train_set.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "test_set = test_set.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f9e192d688c4f87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Réalisation d'un modèle CNN\n",
    "On commence par crée un modèle vide à l'aide de la fonction [`Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) de tensorflow. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a29261e7d996860"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_classes = 5 # Nombre de classes et donc aussi nombre de neurones dans la dernière couche\n",
    "model = Sequential()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "dadbd60a8636b643"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalisation\n",
    "La normalisation consiste juste à diviser l’entrée (la valeur d’une composante RVB d’un pixel) par 255 pour transformer l’entrée dans l’intervalle [0, 1]. On va utiliser la couche [`layers.experimental.preprocessing.Rescaling`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Rescaling) à cet effet."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7251b9b71c13653b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.add(layers.experimental.preprocessing.Rescaling(1./255))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "cbebbf44b9649bd3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implémentation des couches\n",
    "On va maintenant implémenter dans notre modèle, les différentes couches que nous souhaitons mettre en place :\n",
    "- Un bloc convolutif contenant 16 filtres de hauteur et de largeur 3 avec une couche de Pooling.\n",
    "- Un bloc convolutif similaire au précédent contenant 32 filtres de hauteur et de largeur de 3.\n",
    "- Un bloc convolutif similaire au précédent contenant 64 filtres de hauteur et de largeur de 3.\n",
    "- Une couche contenant la couche précédente aplatie (flatten).\n",
    "- Une couche entièrement connectée de taille 128.\n",
    "- La couche finale complètement connectée (dense) retournant le résultat de la classification."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "683aed2c5026857b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Couche de convolution\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "# Couche de pooling\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# Bloc convolutif ou la taille du filtre est de (32, 3)\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# Bloc convolutif ou la taille du filtre est de (64, 3)\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# Applatissement de la couche\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Couche entièrement connectée (couche dense)\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# Couche entièrement connectée retournant le résultat de la classification\n",
    "model.add(layers.Dense(num_classes))\n",
    "\n",
    "model.build((None, image_h, image_w, 3))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c31dfe85feb177eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complitaion du modèle\n",
    "On va donc ensuite compiler notre modèle"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfe938ae2fc6511f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer =  'adam',\n",
    "              loss =  tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e8bc0dd3cecd81d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Techniques de régularisation\n",
    "Les techniques de régularisation sont les techniques qui visent à réduire le surapprentissage. L’objectif est d’éviter que le réseau de neurones mémorise le jeu de données en s’ajustant bêtement sur les particularités du jeu d’entrainement. Il s’agit globalement de réduire les degrés de liberté du réseau de neurones.\n",
    "\n",
    "Les techniques de régularisation sont les techniques qui visent à réduire le surapprentissage. L’objectif est d’éviter que le réseau de neurones mémorise le jeu de données en s’ajustant bêtement sur les particularités du jeu d’entrainement. Il s’agit globalement de réduire les degrés de liberté du réseau de neurones. Dans le cadre de ce wokrshop nous verrons deux techniques de régularisation :\n",
    "-\t**L’augmentation des données** : Avoir plus de données est toujours bon pour réduire le surapprentissage, d’où l’augmentation des données. Le principe et de rajouter de nouvelles images en effectuant des transformations sur le jeu d’entrainement d’origine. Ces nouvelles images sont obtenues par des transformation affines, ou généralement par des transformations réalistes qui ne change pas la nature du label affectée à l’image. Cette technique est très efficace car les réseaux de neurones sont très gourmands en données.\n",
    "-\t**La technique de dropout** : Cette technique consiste à désactiver, à chaque traitement, les neurones d’une couche dense du réseau de manière aléatoire. Le dropout dépend d’un paramètre qui représente la probabilité de désactivation des neurones de la couche. Cette probabilité est le la proportion moyenne de neurones actives dans la couche durant les itérations de l’entrainement. Elle permet de réduire la complexité du réseau de neurones pour réduire le surapprentissage."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da4d039ec770e096"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.src.layers.preprocessing.image_preprocessing import HORIZONTAL_AND_VERTICAL\n",
    "from keras.src.layers.preprocessing.image_preprocessing import RandomFlip\n",
    "from keras.src.layers.preprocessing.image_preprocessing import RandomRotation\n",
    "from keras.src.layers.preprocessing.image_preprocessing import RandomZoom\n",
    "from keras import Sequential\n",
    "\n",
    "data_augmentation = Sequential(\n",
    "    [\n",
    "        RandomFlip(\n",
    "            mode=HORIZONTAL_AND_VERTICAL,\n",
    "            input_shape=(image_h, image_w, 3)),\n",
    "        RandomRotation(\n",
    "            factor=0.18,\n",
    "            fill_mode='reflect',\n",
    "            interpolation='bilinear',\n",
    "            seed=None,\n",
    "            fill_value=0.0),\n",
    "        RandomZoom(\n",
    "            height_factor=0.1,\n",
    "            width_factor=None,\n",
    "            fill_mode='reflect',\n",
    "            interpolation='bilinear',\n",
    "            seed=None,\n",
    "            fill_value=0.0)\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d959b2e8aa790225"
  },
  {
   "cell_type": "markdown",
   "source": [
    "On crée ensuite notre modèle en y implémentant l'ensemble des couches que nous souhaitons y intégrer :\n",
    "Un bloc convolutif contenant 16 filtres de hauteur et de largeur 3 avec une couche de Pooling.\n",
    "- Un bloc convolutif similaire au précédent contenant 32 filtres de hauteur et de largeur de 3.\n",
    "- Un bloc convolutif similaire au précédent contenant 64 filtres de hauteur et de largeur de 3.\n",
    "- Une couche de DropOut\n",
    "- Une couche contenant la couche précédente aplatie (flatten).\n",
    "- Une couche entièrement connectée de taille 128.\n",
    "- La couche finale complètement connectée (dense) retournant le résultat de la classification.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b0dbc8dc0764203"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Le modèle\n",
    "epochs = 8\n",
    "complete_model =  Sequential([\n",
    "    layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes)\n",
    "])\n",
    "complete_model.build((None, image_h, image_w, 3))\n",
    "# Compilation du modèle\n",
    "complete_model.compile(optimizer =  'adam',\n",
    "                       loss =  tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                       metrics=['accuracy'])\n",
    "# Résumé du modèle\n",
    "complete_model.summary()\n",
    "# Enrainement du modèle\n",
    "history =  complete_model.fit(\n",
    "    train_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=epochs\n",
    ")\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c1934c7ccdfd3ac2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
