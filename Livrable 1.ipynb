{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Projet LEYENDA\n",
    "## Livrable 1 - Classification Binaire"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bbcdab41f7ad26c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Importation des bibliothèques"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7705d02550f9b2d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import zipfile\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T15:05:38.072092900Z",
     "start_time": "2023-10-03T15:05:37.618527400Z"
    }
   },
   "id": "4ff84e3050962ffd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Préparation des images\n",
    "#### Dézip des fichiers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab9c6473dd452b67"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier Dataset Livrable 1 - Photo.zip décompressé dans le dossier Dataset.\n",
      "Fichier Dataset Livrable 1 - Text.zip décompressé dans le dossier Dataset.\n",
      "Fichier Dataset Livrable 1 - Sketch.zip décompressé dans le dossier Dataset.\n",
      "Fichier Dataset Livrable 1 - Schematics.zip décompressé dans le dossier Dataset.\n",
      "Tous les fichiers ZIP ont été décompressés dans le dossier Dataset\n"
     ]
    }
   ],
   "source": [
    "repertoire = './'\n",
    "dossier_dataset = './Data'\n",
    "if not os.path.exists(dossier_dataset):\n",
    "    os.makedirs(dossier_dataset)\n",
    "    \n",
    "for fichier in os.listdir(repertoire):\n",
    "    chemin_fichier = os.path.join(repertoire,fichier)\n",
    "    if zipfile.is_zipfile(chemin_fichier):\n",
    "        with zipfile.ZipFile(chemin_fichier, 'r') as zip_ref:\n",
    "            zip_ref.extractall(dossier_dataset)\n",
    "            print(f'Fichier {fichier} décompressé dans le dossier Dataset.')\n",
    "print('Tous les fichiers ZIP ont été décompressés dans le dossier Dataset')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T15:09:03.420328100Z",
     "start_time": "2023-10-03T15:08:21.550577100Z"
    }
   },
   "id": "f5ec94da62cf051e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Emplacement du dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc79384cddaa1e06"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "datapath = \"./Data/\"\n",
    "data_dir = pathlib.Path(datapath)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T15:10:21.356787400Z",
     "start_time": "2023-10-03T15:10:21.352392600Z"
    }
   },
   "id": "55e8603cf19c764c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Mise à l'échelle des images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d1b5cb91c8d408d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Dossier contenant les images\n",
    "dossier_images = ----------------\n",
    "\n",
    "# Dictionnaire pour stocker le nombre d'images par dimension\n",
    "dimensions_images = {}\n",
    "\n",
    "# Parcourir le dossier\n",
    "for fichier in os.listdir(dossier_images):\n",
    "    chemin_fichier = os.path.join(dossier_images, fichier)\n",
    "\n",
    "    # Vérifier si le fichier est une image\n",
    "    if not os.path.isfile(chemin_fichier) or not fichier.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "        continue\n",
    "\n",
    "    # Ouvrir l'image avec Pillow\n",
    "    try:\n",
    "        image = Image.open(chemin_fichier)\n",
    "    except Exception as e:\n",
    "        print(f\"Impossible d'ouvrir l'image {chemin_fichier}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "    # Obtenir les dimensions de l'image\n",
    "    largeur, hauteur = image.size\n",
    "    dimensions = (largeur, hauteur)\n",
    "\n",
    "    # Compter le nombre d'images avec les mêmes dimensions\n",
    "    if dimensions in dimensions_images:\n",
    "        dimensions_images[dimensions] += 1\n",
    "    else:\n",
    "        dimensions_images[dimensions] = 1\n",
    "\n",
    "# Afficher le résultat\n",
    "for dimensions, nombre in dimensions_images.items():\n",
    "    print(f\"Dimensions {dimensions}: {nombre} images\")\n",
    "\n",
    "# Enregistrez les résultats dans un fichier texte si nécessaire\n",
    "with open(\"resultats_dimensions.txt\", \"w\") as fichier_resultats:\n",
    "    for dimensions, nombre in dimensions_images.items():\n",
    "        fichier_resultats.write(f\"Dimensions {dimensions}: {nombre} images\\n\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4951c25639cf8d58"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Les images n'ont pas de dimension standard, il faut donc les traiter pour obtenir des images aux dimensions identiques afin de pouvoir les utiliser dans nos modèles futurs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64b4613fec0ed4f0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "target_size = (224, 224)\n",
    "for folder_name in os.listdir(base_path):\n",
    "    folder_path = os.path.join(base_path, folder_name)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "        for image_name in os.listdir(folder_path):\n",
    "            image_path = os.path.join(folder_path, image_name)\n",
    "\n",
    "            if image_name.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                image = Image.open(image_path)\n",
    "\n",
    "                # Calculez les coordonnées de recadrage centré pour conserver les parties importantes\n",
    "                width, height = image.size\n",
    "                left = (width - target_size[0]) / 2\n",
    "                top = (height - target_size[1]) / 2\n",
    "                right = (width + target_size[0]) / 2\n",
    "                bottom = (height + target_size[1]) / 2\n",
    "\n",
    "                # Effectuez le recadrage centré\n",
    "                image = image.crop((left, top, right, bottom))\n",
    "\n",
    "                # Redimensionnez l'image à la taille cible\n",
    "                image = image.resize(target_size, Image.ANTIALIAS)\n",
    "\n",
    "                image = np.array(image)  # Convertir en tableau NumPy\n",
    "                image_paths.append(image_path)\n",
    "                labels.append(folder_name)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2d658c3a0c59b73"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ------------------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72490c6d12c01f1"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "image_h = 360\n",
    "image_w = 360\n",
    "batch_s = 32"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T15:10:21.904570Z",
     "start_time": "2023-10-03T15:10:21.899579600Z"
    }
   },
   "id": "2421b5f437d9cb68"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "image_dataset_from_directory() missing 1 required positional argument: 'directory'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Le train_set\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m train_set \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreprocessing\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage_dataset_from_directory\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./Data\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m  \u001B[49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43msubset\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m  \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtraining\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m42\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mimage_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mimage_h\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimage_w\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_s\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Le test_set\u001B[39;00m\n\u001B[1;32m     11\u001B[0m test_set \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mpreprocessing\u001B[38;5;241m.\u001B[39mimage_dataset_from_directory(\n\u001B[1;32m     12\u001B[0m     data_dir,\n\u001B[1;32m     13\u001B[0m     validation_split\u001B[38;5;241m=\u001B[39m  \u001B[38;5;241m0.2\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     17\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_s\n\u001B[1;32m     18\u001B[0m )\n",
      "\u001B[0;31mTypeError\u001B[0m: image_dataset_from_directory() missing 1 required positional argument: 'directory'"
     ]
    }
   ],
   "source": [
    "# Le train_set\n",
    "train_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir = \"./Data\",\n",
    "    validation_split=  0.2,\n",
    "    subset =  \"training\",\n",
    "    seed=42,\n",
    "    image_size=(image_h, image_w),\n",
    "    batch_size=batch_s\n",
    ")\n",
    "# Le test_set\n",
    "test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=  0.2,\n",
    "    subset =  \"validation\",\n",
    "    seed=42,\n",
    "    image_size=(image_h, image_w),\n",
    "    batch_size=batch_s\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T15:10:26.853516Z",
     "start_time": "2023-10-03T15:10:26.833821200Z"
    }
   },
   "id": "ebeaf5921868e37c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_names = train_set.class_names\n",
    "print(class_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-03T13:37:35.928559500Z"
    }
   },
   "id": "ae9a6d420817ad65"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for images, labels in train_set.take(1):\n",
    "    for i in range(9):\n",
    "        ax =  plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-03T13:37:35.928559500Z"
    }
   },
   "id": "7de352088c714a3d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(type(train_set))\n",
    "images, labels =  next(iter(train_set))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-03T13:37:35.928559500Z"
    }
   },
   "id": "1877bff46b0ad885"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_set = train_set.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "test_set = test_set.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-03T13:37:35.933310700Z"
    }
   },
   "id": "f9e192d688c4f87"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_classes = 5 # Nombre de classes et donc aussi nombre de neurones dans la dernière couche\n",
    "model = Sequential()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-03T13:37:35.933310700Z"
    }
   },
   "id": "dadbd60a8636b643"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.add(layers.experimental.preprocessing.Rescaling(1./255))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-03T13:37:35.933310700Z"
    }
   },
   "id": "cbebbf44b9649bd3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Couche de convolution\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "# Couche de pooling\n",
    "model.add(layers.MaxPooling2D((2, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-03T13:37:35.933310700Z"
    }
   },
   "id": "cfd0928113c49f5a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Bloc convolutif ou la taille du filtre est de (32, 3)\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# Bloc convolutif ou la taille du filtre est de (64, 3)\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# Applatissement de la couche\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Couche entièrement connectée (couche dense)\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# Couche entièrement connectée retournant le résultat de la classification\n",
    "model.add(layers.Dense(num_classes))\n",
    "\n",
    "model.build((None, image_h, image_w, 3))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-03T13:37:35.933310700Z"
    }
   },
   "id": "c31dfe85feb177eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer =  'adam',\n",
    "              loss =  tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-03T13:37:35.933310700Z"
    }
   },
   "id": "e8bc0dd3cecd81d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.src.layers.preprocessing.image_preprocessing import HORIZONTAL_AND_VERTICAL\n",
    "from keras.src.layers.preprocessing.image_preprocessing import RandomFlip\n",
    "from keras.src.layers.preprocessing.image_preprocessing import RandomRotation\n",
    "from keras.src.layers.preprocessing.image_preprocessing import RandomZoom\n",
    "from keras import Sequential\n",
    "\n",
    "data_augmentation = Sequential(\n",
    "    [\n",
    "        RandomFlip(\n",
    "            mode=HORIZONTAL_AND_VERTICAL,\n",
    "            input_shape=(image_h, image_w, 3)),\n",
    "        RandomRotation(\n",
    "            factor=0.18,\n",
    "            fill_mode='reflect',\n",
    "            interpolation='bilinear',\n",
    "            seed=None,\n",
    "            fill_value=0.0),\n",
    "        RandomZoom(\n",
    "            height_factor=0.1,\n",
    "            width_factor=None,\n",
    "            fill_mode='reflect',\n",
    "            interpolation='bilinear',\n",
    "            seed=None,\n",
    "            fill_value=0.0)\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-03T13:37:35.933310700Z"
    }
   },
   "id": "d959b2e8aa790225"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Le modèle\n",
    "epochs = 8\n",
    "complete_model =  Sequential([\n",
    "    layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes)\n",
    "])\n",
    "complete_model.build((None, image_h, image_w, 3))\n",
    "# Compilation du modèle\n",
    "complete_model.compile(optimizer =  'adam',\n",
    "                       loss =  tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                       metrics=['accuracy'])\n",
    "# Résumé du modèle\n",
    "complete_model.summary()\n",
    "# Enrainement du modèle\n",
    "history =  complete_model.fit(\n",
    "    train_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=epochs\n",
    ")\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-03T13:37:35.933310700Z"
    }
   },
   "id": "c1934c7ccdfd3ac2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-03T13:37:35.933310700Z"
    }
   },
   "id": "976d5e14d0cf651"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
