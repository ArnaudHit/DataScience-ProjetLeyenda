{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10586ddc4e0417b6"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 14:20:04.800952: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-24 14:20:04.801002: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-24 14:20:04.802955: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-24 14:20:05.049638: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import collections\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import zipfile\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T14:20:11.693765700Z",
     "start_time": "2023-10-24T14:20:03.101106100Z"
    }
   },
   "id": "5fca277094268aa0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chargement des données"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d8f41b0cfff98d4"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier train2014.zip décompressé dans le dossier Dataset.\n",
      "Tous les fichiers ZIP ont été décompressés dans le dossier Dataset\n"
     ]
    }
   ],
   "source": [
    "repertoire = './Train2014Zip'\n",
    "dossier_dataset = './train2014'\n",
    "if not os.path.exists(dossier_dataset):\n",
    "    os.makedirs(dossier_dataset)\n",
    "\n",
    "for fichier in os.listdir(repertoire):\n",
    "    chemin_fichier = os.path.join(repertoire,fichier)\n",
    "    if zipfile.is_zipfile(chemin_fichier):\n",
    "        with zipfile.ZipFile(chemin_fichier, 'r') as zip_ref:\n",
    "            zip_ref.extractall(dossier_dataset)\n",
    "            print(f'Fichier {fichier} décompressé dans le dossier Dataset.')\n",
    "print('Tous les fichiers ZIP ont été décompressés dans le dossier Dataset')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T13:30:07.919669900Z",
     "start_time": "2023-10-24T13:23:30.650851600Z"
    }
   },
   "id": "6741f00eb709c661"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Chemin du fichier d'annotations\n",
    "annotation_folder = \"/annotations/\"\n",
    "annotation_file = os.path.abspath('.')+\"/annotations/captions_train2014.json\"\n",
    "\n",
    "# Chemin du dossier contenant les images à annoter\n",
    "image_folder = '/train2014/train2014/'\n",
    "PATH = os.path.abspath('.') + image_folder\n",
    "\n",
    "# Lecture du fichier d'annotation\n",
    "with open(annotation_file, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# Grouper toutes les annotations ayant le meme identifiant.\n",
    "image_path_to_caption = collections.defaultdict(list)\n",
    "for val in annotations['annotations']:\n",
    "    # marquer le debut et la fin de chaque annotation\n",
    "    caption = f\"<start> {val['caption']} <end>\"\n",
    "    # L'identifiant d'une image fait partie de son chemin d'accès\n",
    "    image_path = PATH + 'COCO_train2014_' + '%012d.jpg' % (val['image_id'])\n",
    "    # Rajout du caption associé à image_path\n",
    "    image_path_to_caption[image_path].append(caption)\n",
    "\n",
    "# Prendre les premières images seulement\n",
    "image_paths = list(image_path_to_caption.keys())\n",
    "train_image_paths = image_paths\n",
    "\n",
    "# Liste de toutes les annotations\n",
    "train_captions = []\n",
    "# Liste de tous les noms de fichiers des images dupliquées (en nombre d'annotations par image)\n",
    "img_name_vector = []\n",
    "\n",
    "for image_path in train_image_paths:\n",
    "    caption_list = image_path_to_caption[image_path]\n",
    "    # Rajout de caption_list dans train_captions\n",
    "    train_captions.extend(caption_list)\n",
    "    # Rajout de image_path dupliquée len(caption_list) fois\n",
    "    img_name_vector.extend([image_path] * len(caption_list))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T14:21:28.141204300Z",
     "start_time": "2023-10-24T14:21:27.037535800Z"
    }
   },
   "id": "162c27cf327c80e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 14:21:36.257570: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-24 14:21:36.481410: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-24 14:21:36.481448: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-24 14:21:36.482449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-24 14:21:36.482485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-24 14:21:36.482506: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-24 14:21:38.189464: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-24 14:21:38.189503: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-24 14:21:38.189511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-24 14:21:38.189541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-24 14:21:38.189555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6599 MB memory:  -> device: 0, name: Quadro P4000, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "  0%|                                                                                          | 0/5174 [00:00<?, ?it/s]2023-10-24 14:21:43.164821: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      " 50%|███████████████████████████████████████▏                                       | 2565/5174 [10:30<06:48,  6.38it/s]"
     ]
    }
   ],
   "source": [
    "# Telechargement du modèle InceptionV3 pré-entrainé avec la cassification sur ImageNet\n",
    "image_model = tf.keras.applications.InceptionV3(include_top=False,\n",
    "                                                weights='imagenet')\n",
    "# Creation d'une variable qui sera l'entrée du nouveau modèle de pre-traitement d'images\n",
    "new_input = image_model.input\n",
    "# récupérer la dernière couche caché qui contient l'image en representation compacte\n",
    "hidden_layer = image_model.layers[-1].output\n",
    "\n",
    "# Modèle qui calcule une representation dense des images avec InceptionV3\n",
    "image_features_extract_model = tf.keras.Model(new_input, hidden_layer)\n",
    "\n",
    "# Définition de la fonction load_image\n",
    "def load_image(image_path):\n",
    "    \"\"\"\n",
    "    La fonction load_image a pour entrée le chemin d'une image et pour sortie un couple\n",
    "    contenant l'image traitée ainsi que son chemin d'accès.\n",
    "    La fonction load_image effectue les traitement suivant:\n",
    "        1. Chargement du fichier correspondant au chemin d'accès image_path\n",
    "        2. Décodage de l'image en RGB.\n",
    "        3. Redimensionnement de l'image en taille (299, 299).\n",
    "        4. Normalisation des pîxels de l'image entre -1 et 1\n",
    "    \"\"\"\n",
    "    # Lecture du fichier image\n",
    "    img = tf.io.read_file(image_path)\n",
    "    # Decodage de l'image en RGB\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Redimensionnement de l'image en taille (299, 299)\n",
    "    img = tf.image.resize(img, (299, 299))\n",
    "    # Normalisation des pîxels de l'image entre -1 et 1\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    return img, image_path\n",
    "\n",
    "# Pré-traitement des images\n",
    "# Prendre les noms des images\n",
    "encode_train = sorted(set(img_name_vector))\n",
    "\n",
    "# Creation d'une instance de \"tf.data.Dataset\" partant des noms des images \n",
    "image_dataset = tf.data.Dataset.from_tensor_slices(encode_train)\n",
    "# Division du données en batchs après application du pré-traitement fait par load_image\n",
    "image_dataset = image_dataset.map(\n",
    "    load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(16)\n",
    "\n",
    "# Parcourir le dataset batch par batch pour effectuez le pré-traitement d'InceptionV3\n",
    "for img, path in tqdm(image_dataset):\n",
    "    # Pré-traitement du batch (de taille (16,8,8,2048)) courant par InceptionV3 \n",
    "    batch_features = image_features_extract_model(img)\n",
    "    # Resize du batch de taille (16,8,8,2048) en taille (16,64,2048)\n",
    "    batch_features = tf.reshape(batch_features,\n",
    "                                (batch_features.shape[0], -1, batch_features.shape[3]))\n",
    "    # Parcourir le batch courant et stocker le chemin ainsi que le batch avec np.save()\n",
    "    for bf, p in zip(batch_features, path):\n",
    "        path_of_feature = p.numpy().decode(\"utf-8\")\n",
    "        # (chemin de l'image associe a sa nouvelle representation , representation de l'image)\n",
    "        np.save(path_of_feature, bf.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-24T14:21:35.942806900Z"
    }
   },
   "id": "4dfb2e345995a030"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pré-traitement des annotations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ff0e3f7ea2589fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Trouver la taille maximale \n",
    "def calc_max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "# Chosir les 5000 mots les plus frequents du vocabulaire\n",
    "top_k = 5000\n",
    "#La classe Tokenizer permet de faire du pre-traitement de texte pour reseau de neurones \n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k,\n",
    "                                                  oov_token=\"<unk>\",\n",
    "                                                  filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "# Construit un vocabulaire en se basant sur la liste train_captions\n",
    "tokenizer.fit_on_texts(train_captions)\n",
    "\n",
    "# Créer le token qui sert à remplir les annotations pour egaliser leurs longueur\n",
    "tokenizer.word_index['<pad>'] = 0\n",
    "tokenizer.index_word[0] = '<pad>'\n",
    "\n",
    "# Creation des vecteurs(liste de token entiers) à partir des annotations (liste de mots)\n",
    "train_seqs = tokenizer.texts_to_sequences(train_captions)\n",
    "\n",
    "# Remplir chaque vecteur à jusqu'à la longueur maximale des annotations\n",
    "cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')\n",
    "\n",
    "# Calcule la longueur maximale qui est utilisée pour stocker les poids d'attention \n",
    "# Elle servira plus tard pour l'affichage lors de l'évaluation\n",
    "max_length = calc_max_length(train_seqs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49df4f361d22b0ed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
